{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/Mint/Desktop/ML包/newgenie/')\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "\n",
    "import utils3.misc_utils as mu\n",
    "import utils3.summary_statistics as ss\n",
    "\n",
    "#from utils3.feature_select import *  # from ml\n",
    "import utils3.feature_selection as fs  # from genie\n",
    "fs_obj = fs.FeatureSelection()\n",
    "import utils3.metrics as mt\n",
    "pf = mt.Performance()\n",
    "bw = mt.BinWoe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "INPUT_PATH = 'C:\\\\Users\\\\Mint\\\\Documents\\\\Python Scripts\\\\02_模型\\\\04genie&machinelearning包'\n",
    "RESULT_PATH = 'C:\\\\Users\\\\Mint\\\\Documents\\\\Python Scripts\\\\02_模型\\\\04genie&machinelearning包'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_excel(os.path.join(INPUT_PATH, '1121data.xlsx'), dtype={'order_no':object})\n",
    "data_all.shape\n",
    "data_all.label.value_counts(dropna = False)\n",
    "data_all.set_index([\"order_no\"], inplace=True)\n",
    "\n",
    "#d.rename(columns = {'effective_date':'applied_at', 'business_id':'applied_from', 'fst_term_late_day':'passdue_day', 'ever7':'label'}, inplace=True)\n",
    "data_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils3.generate_report as gr\n",
    "#train_test = df_all[df_all.sample_set != 'oot']\n",
    "cnt_label,cnt_month, cnt_qudao = gr.describe_sample(data_all)\n",
    "\n",
    "cnt_label\n",
    "cnt_month\n",
    "cnt_qudao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all.drop(['month', 'label_7','label_15'],axis=1)\n",
    "data_all.shape\n",
    "\n",
    "base_col = ['applied_at','applied_from','applied_type','passdue_day', 'sample_set']\n",
    "x_col = list(set(list(data_all.columns))-set(base_col)-set(['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = pd.DataFrame(columns=['数据源', '指标英文', '指标中文', '数据类型', '指标类型'])\n",
    "var_dict['数据源'] = x_col\n",
    "var_dict['指标英文'] = x_col\n",
    "var_dict['指标中文'] = x_col\n",
    "var_dict['数据类型'] = 'float'\n",
    "var_dict['数据类型'] = '原始字段'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = pd.read_excel(os.path.join(INPUT_PATH, '建模代码可用变量字典 20191106.xlsx'), sheet_name = '02_字典')\n",
    "var_dict = var_dict[var_dict.指标英文.isin(x_col)]\n",
    "var_dict.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "utils3.misc_utils.process_missing\n",
    "    处理缺失值。\n",
    "    -8888: 如果某个数据源整条数据都没有就算是完整缺失未查得。\n",
    "    -8887: 个别变量值缺失。\n",
    "\n",
    "    Args:\n",
    "    X (pd.DataFrame): 原始数值的分类变量\n",
    "    var_dict (pd.DataFrame): 标准数据字典，需包含数据源，指标英文两列。\n",
    "    known_missing (dict): 已知的代表缺失的值以及想要替换成的值。格式为：\n",
    "        {-1: -9999, -9999999: -8887}\n",
    "    downflagmap (dict): 中间层有些数据源有downflag字段用来标注是否宕机，是否查无此人等。\n",
    "        格式为：\n",
    "        {'Anrong_DownFlag': {1: -9999}, 'Tongdun_DownFlag': {1: -9999}}\n",
    "\"\"\"  \n",
    "\n",
    "X_cleaned = mu.process_missing(X = data_all,var_dict=var_dict, known_missing={-1:-9999, '-1':-9999}, downflagmap={}, verbose=True)\n",
    "X_cleaned.head()\n",
    "\n",
    "X_cleaned_sorted = X_cleaned.reindex(data_all.index.tolist())\n",
    "data_cleaned = pd.concat([data_all[base_col+['label']], X_cleaned_sorted], axis=1)\n",
    "data_cleaned = data_cleaned[data_all.columns.tolist()]\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "utils3.summary_statistics.eda\n",
    "    X (pd.DataFrame()): 是一个宽表，每一列是一个变量，每一行是一个obs\n",
    "    var_dict (pd.DataFrame()): 标准变量字典表，需包含以下这些列：数据源，指标英文，指标中文，数据类型，指标类型。\n",
    "    useless_vars (list): 无用变量名list\n",
    "    exempt_vars (list): 豁免变量名list，这些变量即使一开始被既定原因定为exclude，也会被保留，比如前一版本模型的变量\n",
    "    data_path (str): 存储数据文件路径\n",
    "    save_label (str): summary文档存储将用'%s_variables_summary.xlsx' % save_label存\n",
    "    uniqvalue_cutoff（float): 0-1之间，缺失率和唯一值阈值设定\n",
    "\n",
    "* 无用变量标记（excelusion_reason）：缺失比例大于阈值，0值比例大于阈值，类别变量类别个数=1/>100\n",
    "* 识别类别变量：①字典中数据类型为varchar,②dtype为object\n",
    "\"\"\"          \n",
    "\n",
    "ss.eda(X = data_cleaned, var_dict=var_dict, data_path = RESULT_PATH, useless_vars = [],exempt_vars = [], save_label ='1128', uniqvalue_cutoff=0.97)\n",
    "summary = pd.read_excel(os.path.join(INPUT_PATH, '1128_variables_summary.xlsx'), encoding='utf-8')\n",
    "\n",
    "eda_remove = summary.loc[summary.exclusion_reason.notnull(), '指标英文'].tolist()\n",
    "len(eda_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分train test testnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = data_cleaned.copy()\n",
    "#df_all = df_all.fillna(-1)\n",
    "df_all = df_all.replace([-9999,'-9999',-8888,'-8888',-8887,'-8887'],[-1,-1,-1,-1,-1,-1])\n",
    "\n",
    "\n",
    "train_df = df_all[df_all.sample_set == 'train']\n",
    "test_df = df_all[df_all.sample_set == 'test']\n",
    "testnew_df = df_all[df_all.sample_set == 'oot']\n",
    "\n",
    "train_df.shape\n",
    "train_df.label.value_counts(dropna = False)\n",
    "#train_df.head()\n",
    "test_df.shape\n",
    "test_df.label.value_counts(dropna = False)\n",
    "#test_df.head()\n",
    "testnew_df.shape\n",
    "testnew_df.label.value_counts(dropna = False)\n",
    "#testnew_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Univariate Chart (all)\n",
    "import utils3.plot_tools as pt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIG_PATH = os.path.join(RESULT_PATH, 'figure', 'UniVarChart')\n",
    "if not os.path.exists(FIG_PATH):\n",
    "    os.makedirs(FIG_PATH)\n",
    "\n",
    "for i in x_col:\n",
    "    pt.univariate_chart(df_all, i,  'label', n_bins=10,\n",
    "                     default_value=-1,\n",
    "                     dftrain=train_df, dftest=test_df,\n",
    "                     draw_all=True, draw_train_test=True)\n",
    "    path = os.path.join(FIG_PATH,\"uniVarChart_\"+i+\".png\")\n",
    "    plt.savefig(path,format='png', dpi=100)\n",
    "    plt.close()\n",
    "    print(i+': done')\n",
    "    \n",
    "train_df = train_df.drop(['bins','bin_no'],axis=1)\n",
    "test_df = test_df.drop(['bins','bin_no'],axis=1)\n",
    "\n",
    "train_df.shape\n",
    "test_df.shape\n",
    "testnew_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.drop(base_col, axis=1)\n",
    "test = test_df.drop(base_col, axis=1)\n",
    "testnew = testnew_df.drop(base_col, axis=1)\n",
    "train.head()\n",
    "train.shape\n",
    "\n",
    "# 若EDA有需要删除的变量\n",
    "train = train.drop(eda_remove, axis=1)\n",
    "test = test.drop(eda_remove, axis=1)\n",
    "testnew = testnew.drop(eda_remove, axis=1)\n",
    "\n",
    "X_train = train.drop(['label'], axis=1)\n",
    "y_train = train.label\n",
    "X_test = test.drop(['label'], axis=1)\n",
    "y_test = test.label\n",
    "X_testnew = testnew.drop(['label'], axis=1)\n",
    "y_testnew = testnew.label\n",
    "\n",
    "X_train.shape\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "## prediction\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "## evaluation\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "features_in_model = list(X_train.columns)\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "var_importance = pd.DataFrame(columns=[\"指标英文\", 'importance'])\n",
    "var_importance['指标英文'] = features_in_model\n",
    "var_importance['importance'] = feature_importance\n",
    "var_importance.loc[:, 'importance_rank'] = var_importance.importance.rank(ascending=False)\n",
    "var_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量分布及各项指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "args_dict = {\n",
    "    'random_forest': {\n",
    "        'grid_search': False,\n",
    "        'param': None\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'grid_search': False,\n",
    "        'param': None\n",
    "    }\n",
    "}\n",
    "methods = [\n",
    "    'random_forest',\n",
    "    #'lasso',\n",
    "    'xgboost'\n",
    "]\n",
    "\n",
    "\n",
    "## Train 分箱\n",
    "model_train_final = train.copy()\n",
    "features_var_dict = list(var_dict['指标英文'])\n",
    "X_train_IV = model_train_final[features_var_dict]\n",
    "y_train_IV = model_train_final['label'].astype(int)\n",
    "\n",
    "X_cat_train, X_transformed_train, woe_iv_df_train, rebin_spec_train, ranking_result_train = fs_obj.overall_ranking(X_train_IV, y_train_IV,\n",
    "                                                                                           var_dict, args_dict,\n",
    "                                                                                           methods, num_max_bins=5)\n",
    "\n",
    "rebin_spec = mu.convert_rebin_spec2XGB_rebin_spec(rebin_spec_train)\n",
    "rebin_spec_bin_adjusted = {k: v for k, v in rebin_spec.items() if k in features_var_dict}\n",
    "\n",
    "## 输出变量的分箱\n",
    "X_cat_train = bw.convert_to_category(\n",
    "    model_train_final[features_var_dict],\n",
    "    var_dict,\n",
    "    rebin_spec_bin_adjusted)\n",
    "\n",
    "model_test_final = test.copy()\n",
    "X_cat_test = bw.convert_to_category(\n",
    "    model_test_final[features_var_dict],\n",
    "    var_dict,\n",
    "    rebin_spec_bin_adjusted)\n",
    "\n",
    "model_testnew_final = testnew.copy()\n",
    "X_cat_testnew = bw.convert_to_category(\n",
    "    model_testnew_final[features_var_dict],\n",
    "    var_dict,\n",
    "    rebin_spec_bin_adjusted)\n",
    "\n",
    "# 变量分布\n",
    "## train\n",
    "train['appmon'] = '0_train'\n",
    "var_cols = set(X_train.columns).intersection(var_dict.指标英文)\n",
    "X_cat_train_with_y_appmon = pd.merge(X_cat_train,train[['label','appmon']] ,left_index=True,right_index=True)\n",
    "var_dist_badRate_by_time = ss.get_badRate_and_dist_by_time(X_cat_train_with_y_appmon,var_cols,'appmon','label')\n",
    "\n",
    "## test\n",
    "test['appmon'] = '1_test'\n",
    "X_cat_test_with_y_appmon = pd.merge(X_cat_test,test[['label','appmon']],left_index=True,right_index=True)\n",
    "var_dist_badRate_by_time_test = ss.get_badRate_and_dist_by_time(X_cat_test_with_y_appmon,var_cols,'appmon','label')\n",
    "\n",
    "## testnew\n",
    "testnew['appmon'] = '2_testnew'\n",
    "X_cat_testnew_with_y_appmon = pd.merge(X_cat_testnew,testnew[['label','appmon']],left_index=True,right_index=True)\n",
    "var_dist_badRate_by_time_testnew = ss.get_badRate_and_dist_by_time(X_cat_testnew_with_y_appmon,var_cols,'appmon','label')\n",
    "\n",
    "## all\n",
    "all_cat = pd.concat([X_cat_train,X_cat_test,X_cat_testnew])\n",
    "app_data = pd.concat([train[['label','appmon']],test[['label','appmon']],testnew[['label','appmon']]])\n",
    "X_cat_with_y_appmon_all = pd.merge(all_cat,app_data[['label','appmon']] ,left_index=True,right_index=True)\n",
    "var_dist_badRate_by_time_all = ss.get_badRate_and_dist_by_time(X_cat_with_y_appmon_all,var_cols,'appmon','label')\n",
    "var_dist_badRate_by_time_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LR: X_transformed_test, X_transformed_testnew\n",
    "\n",
    "## Test 分箱\n",
    "X_test_IV = model_test_final[features_var_dict].astype(float)\n",
    "y_test_IV = model_test_final['label'].astype(int)\n",
    "X_cat_test, X_transformed_test, woe_iv_df_test, rebin_spec_test, ranking_result_test = fs_obj.overall_ranking(X_test_IV, y_test_IV,\n",
    "                                                                                           var_dict, args_dict,\n",
    "                                                                                           methods, num_max_bins=5)\n",
    "## Testnew 分箱\n",
    "X_testnew_IV = model_testnew_final[features_var_dict].astype(float)\n",
    "y_testnew_IV = model_testnew_final['label'].astype(int)\n",
    "X_cat_testnew, X_transformed_testnew, woe_iv_df_testnew, rebin_spec_testnew, ranking_result_testnew = fs_obj.overall_ranking(X_testnew_IV, y_testnew_IV,\n",
    "                                                                                           var_dict, args_dict,\n",
    "                                                                                           methods, num_max_bins=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI\n",
    "var_psi = pf.variable_psi(X_cat_train, X_cat_test, var_dict)\n",
    "var_psi.loc[:, 'psi_rank'] = var_psi.PSI.rank(ascending=False)\n",
    "var_psi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总各项指标\n",
    "ranking_result = ranking_result_train.merge(var_psi, on='指标英文', how='left')\\\n",
    "                                      .merge(var_importance, on='指标英文', how='left')\n",
    "#ranking_result.columns\n",
    "ranking_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.columns\n",
    "#train.shape\n",
    "train = train.drop(['appmon'],axis=1)\n",
    "test = test.drop(['appmon'],axis=1)\n",
    "testnew = testnew.drop(['appmon'],axis=1)\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "testnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rmv = fs.feature_remove(train,test, ranking_result, RESULT_PATH, psi = 0.1, iv = 0, imp = 0, corr = 1, slope = 'FALSE')\n",
    "#len(f_rmv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train = train.drop(['slope'], axis=1)\n",
    "    test = test.drop(['slope'], axis=1)\n",
    "    #testnew = testnew.drop(['slope'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "testnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train.drop(f_rmv, axis=1)\n",
    "test_2 = test.drop(f_rmv, axis=1)\n",
    "testnew_2 = testnew.drop(f_rmv, axis=1)\n",
    "\n",
    "train_2.shape\n",
    "test_2.shape\n",
    "testnew_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = X_transformed_train.reindex(train_2.index.tolist())\n",
    "X_test_LR = X_transformed_test.reindex(test_2.index.tolist())\n",
    "X_testnew_LR = X_transformed_testnew.reindex(testnew_2.index.tolist())\n",
    "y_train = train_2.label\n",
    "y_test = test_2.label\n",
    "y_testnew = testnew_2.label\n",
    "\n",
    "X_train_LR.head()\n",
    "#X_test_LR.head()\n",
    "#X_testnew_LR.head()\n",
    "\n",
    "features_used = X_train_LR.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils3.modeling\n",
    "lrr = utils3.modeling.LogisticModel(var_dict, y_train, y_test)\n",
    "LR_model, result_dict = lrr.fit_model('LR1', X_train_LR, X_test_LR, features_used)\n",
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coef = result_dict['train_coef']\n",
    "#test_coef = result_dict['train_coef']\n",
    "model_importance = train_coef[['coef']].drop(['const'],axis=0).reset_index()\n",
    "model_importance.rename(columns = {'index':'varName', 'coef':'importance'}, inplace=True)\n",
    "model_importance['importance'] = model_importance['importance'].astype('float64')\n",
    "\n",
    "train_coef.head()\n",
    "train_coef.shape\n",
    "model_importance.head()\n",
    "model_importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_train_pred = result_dict['p_train']\n",
    "y_test_pred = result_dict['p_test']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_testnew_LR = sm.add_constant(X_testnew_LR)\n",
    "y_testnew_pred = LR_model.predict(X_testnew_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 打分&KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.concat([train_df[base_col+['label']], X_train_LR], axis=1)\n",
    "train_pred['y_pred'] = y_train_pred\n",
    "\n",
    "test_pred = pd.concat([test_df[base_col+['label']], X_test_LR], axis=1)\n",
    "test_pred['y_pred'] = y_test_pred\n",
    "\n",
    "testnew_pred = pd.concat([testnew_df[base_col+['label']], X_testnew_LR], axis=1)\n",
    "testnew_pred['y_pred'] = y_testnew_pred\n",
    "\n",
    "train_pred.head()\n",
    "#test_pred.head()\n",
    "#testnew_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc accuracy score 10分箱 20分箱 加入base_col\n",
    "data_scored_train, auc_train, acc_train = pf.data_scored(train_pred, feature_used = features_used)\n",
    "data_scored_test, auc_test, acc_test = pf.data_scored(test_pred, feature_used = features_used)\n",
    "data_scored_testnew, auc_testnew, acc_testnew = pf.data_scored(testnew_pred, feature_used = features_used)\n",
    "\n",
    "data_scored_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS\n",
    "# train & test\n",
    "train_proba_ks, test_proba_ks, train_proba_bin = pf.KS_table(data_scored_train, data_scored_test, q=10, method=\"proba\")\n",
    "train_proba_ks_20, test_proba_ks_20, train_proba_bin_20 = pf.KS_table(data_scored_train, data_scored_test, q=20, method=\"proba\")\n",
    "\n",
    "train_score_ks, test_score_ks, train_score_bin = pf.KS_table(data_scored_train, data_scored_test, q=10, method=\"score\")\n",
    "train_score_ks_20, test_score_ks_20, train_score_bin_20 = pf.KS_table(data_scored_train, data_scored_test, q=20, method=\"score\")\n",
    "\n",
    "# train & OOT\n",
    "train_proba_ks, testnew_proba_ks, train_proba_bin = pf.KS_table(data_scored_train, data_scored_testnew, q=10, method=\"proba\")\n",
    "train_proba_ks_20, testnew_proba_ks_20, train_proba_bin_20 = pf.KS_table(data_scored_train, data_scored_testnew, q=20, method=\"proba\")\n",
    "\n",
    "train_score_ks, testnew_score_ks, train_score_bin = pf.KS_table(data_scored_train, data_scored_testnew, q=10, method=\"score\")\n",
    "train_score_ks_20, testnew_score_ks_20, train_score_bin_20 = pf.KS_table(data_scored_train, data_scored_testnew, q=20, method=\"score\")\n",
    "\n",
    "train_proba_ks\n",
    "test_proba_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### excel集合结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 变量分布\n",
    "var_dist_badRate_by_time_all['used_in_model'] = var_dist_badRate_by_time_all.varName.apply(lambda x: x in features_used)\n",
    "\n",
    "## ranking result\n",
    "ranking_result['used_in_model'] = ranking_result.指标英文.apply(lambda x: x in features_used)\n",
    "\n",
    "## AUC + ACCURACY\n",
    "auc_list = [auc_train, auc_test, auc_testnew]\n",
    "acc_list = [acc_train, acc_test, acc_testnew]\n",
    "split_list = ['train','test','oot']\n",
    "df_auc_acc = pd.DataFrame({\"sample_set\":split_list,\"auc\":auc_list,\"accuracy\":acc_list})\n",
    "\n",
    "## df_prediction\n",
    "all_pred = pd.concat([train_pred, test_pred, testnew_pred]).reset_index()\n",
    "all_pred['order_no'] = all_pred['order_no'].astype(str)\n",
    "\n",
    "## data_scored\n",
    "data_scored_train['sample_set'] = \"train\"\n",
    "data_scored_test['sample_set'] = \"test\"\n",
    "data_scored_testnew['sample_set'] = \"oot\"\n",
    "#data_scored_all = pd.concat([data_scored_train, data_scored_test])\n",
    "data_scored_all = pd.concat([data_scored_train, data_scored_test, data_scored_testnew])\n",
    "data_scored_all['order_no'] = data_scored_all['order_no'].astype(str)\n",
    "\n",
    "# python3.6的dict是ordered，按照顺序这样定义，之后生成excel的时候会按照顺序创建sheet\n",
    "lr_dict = {}\n",
    "\n",
    "# 如果sheet对应的内容是dict，则dict的key会出现在sheet第一列。value会从第二列开始插入\n",
    "# 如果sheet对应的内容是df，则从sheet的A1位置开始插入整张表格，不包含pd.DataFrame的index\n",
    "lr_dict['01_sample_desc'] = {'整体':cnt_label,\n",
    "                              '按月份':cnt_month,\n",
    "                              '按渠道':cnt_qudao\n",
    "                             }\n",
    "lr_dict['02_AUC&ACC'] = df_auc_acc\n",
    "lr_dict['03_EDA'] = summary\n",
    "lr_dict['04_KS'] = {'train_proba_ks':train_proba_ks,\n",
    "                     'test_proba_ks':test_proba_ks,\n",
    "                     'testnew_proba_ks':testnew_proba_ks,\n",
    "                     'train_score_ks':train_score_ks,\n",
    "                     'test_score_ks':test_score_ks,\n",
    "                     'testnew_score_ks':testnew_score_ks,\n",
    "                     'train_proba_ks_20':train_proba_ks_20,\n",
    "                     'test_proba_ks_20':test_proba_ks_20,\n",
    "                     'testnew_proba_ks_20':testnew_proba_ks_20,\n",
    "                     'train_score_ks_20':train_score_ks_20,\n",
    "                     'test_score_ks_20':test_score_ks_20,\n",
    "                     'testnew_score_ks_20':testnew_score_ks_20\n",
    "                      }\n",
    "lr_dict['05_model_importance'] = model_importance.reset_index()\n",
    "lr_dict['06_coef'] = train_coef\n",
    "lr_dict['07_ranking_result'] = ranking_result\n",
    "lr_dict['08_data_scored'] = data_scored_all\n",
    "lr_dict['09_data_prediction'] = all_pred\n",
    "lr_dict['10_woe_iv_train'] = woe_iv_df_train\n",
    "lr_dict['11_var_dist_badRate'] = var_dist_badRate_by_time_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "import utils3.filing as fl\n",
    "\n",
    "FILE_NAME = \"lr_%d_%s\"%(len(features_used), datetime.now().strftime('%y%m%d_%H%M%S'))\n",
    "\n",
    "## SAVE MODEL\n",
    "pickle.dump(LR_model, open(os.path.join(RESULT_PATH, FILE_NAME+\".pkl\"), \"wb\"))\n",
    "\n",
    "## 生成EXCEL\n",
    "#result_path：excel的输出目录\n",
    "#fig_path：KS、AUC、score_dis图片的存储主目录，也就是到figure目录即可\n",
    "#file_name：统计结果的名称，例如：“summary.xlsx”\n",
    "#data_dic:所有数据的汇总字典\n",
    "fl.ModelSummary2Excel(result_path = RESULT_PATH, fig_path= RESULT_PATH, file_name = FILE_NAME+\".xlsx\", data_dic = lr_dict).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
