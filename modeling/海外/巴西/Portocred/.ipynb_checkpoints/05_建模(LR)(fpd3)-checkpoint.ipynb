{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 更新.pyc文件\n",
    "# import compileall\n",
    "# compileall.compile_dir(r'/Users/yantingting/PycharmProjects/modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imp import reload\n",
    "import pickle\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/yantingting/PycharmProjects/modeling')\n",
    "import plot_tools as pt\n",
    "import plotting as pl\n",
    "import metrics as mt\n",
    "from metrics import *\n",
    "import misc_utils as mu\n",
    "import database_conncet as data_con\n",
    "import summary_statistics as ss\n",
    "import feature_selection as fs\n",
    "from feature_selection import *\n",
    "from data_io_utils import *\n",
    "import data_processing as dp\n",
    "import generate_report as gr\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "fs_obj = fs.FeatureSelection()\n",
    "pf = mt.Performance()\n",
    "bw = mt.BinWoe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/Users/yantingting/Seafile/风控/模型/14 巴西/Portocred/data/'\n",
    "result_path = os.path.join('/Users/yantingting/Seafile/风控/模型/14 巴西/Portocred/','模型_LR(5)/') \n",
    "if not os.path.exists(result_path):\n",
    "    os.mkdir(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据&核验数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 449)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(445, 449)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = load_data_from_pickle(input_path,'df_var_all.pkl') \n",
    "# all_df = load_data_from_pickle('/Users/yantingting/Seafile/风控/模型/14 巴西/Portocred/模型_LR(1)/','all_all_original.pkl') \n",
    "all_df.index = all_df.loan_id\n",
    "all_df.shape\n",
    "all_df.rename(columns = {'date':'applied_at', 'fpd_3':'label'}, inplace=True)\n",
    "all_df = all_df.loc[all_df.label.isin([0,1])]\n",
    "all_df.shape\n",
    "eda = ss.eda(all_df , result_path)\n",
    "all_df.fillna(-1,inplace = True)\n",
    "y_col = ['label']\n",
    "useless_col = ['loan_id','applied_at','sample_flag','occupation_Capitalista rend aplic / aluguel','fpd_1','fpd_2']\n",
    "x_col = list(set(all_df.columns)-set(useless_col)-set(y_col))\n",
    "len(x_col)\n",
    "save_data_to_pickle(all_df,result_path,'all_original.pkl')\n",
    "for cols in x_col:\n",
    "    try:\n",
    "        all_df[cols] = all_df[cols].astype(float)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443, 5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>数据源</th>\n",
       "      <th>指标英文</th>\n",
       "      <th>指标中文</th>\n",
       "      <th>数据类型</th>\n",
       "      <th>指标类型</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>serasa_score_y</td>\n",
       "      <td>serasa_score_y</td>\n",
       "      <td>int64</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank</td>\n",
       "      <td>boa_vista_(bvs)_score_y</td>\n",
       "      <td>boa_vista_(bvs)_score_y</td>\n",
       "      <td>int64</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank</td>\n",
       "      <td>internal_score_y</td>\n",
       "      <td>internal_score_y</td>\n",
       "      <td>int64</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank</td>\n",
       "      <td>age</td>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bank</td>\n",
       "      <td>social_status</td>\n",
       "      <td>social_status</td>\n",
       "      <td>int64</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    数据源                     指标英文                     指标中文   数据类型  指标类型\n",
       "0  bank           serasa_score_y           serasa_score_y  int64  bank\n",
       "1  bank  boa_vista_(bvs)_score_y  boa_vista_(bvs)_score_y  int64  bank\n",
       "2  bank         internal_score_y         internal_score_y  int64  bank\n",
       "3  bank                      age                      age  int64  bank\n",
       "4  bank            social_status            social_status  int64  bank"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#字典\n",
    "var_dict = pd.read_csv(os.path.join(input_path,'dict_all.csv'))\n",
    "var_dict['指标类型'] = var_dict['数据源']\n",
    "var_dict.shape\n",
    "var_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 449)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1     76\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112, 449)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    87\n",
       "1    25\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分训练和验证\n",
    "train_df = all_df[all_df.sample_flag == 0]\n",
    "test_df = all_df[all_df.sample_flag == 1]\n",
    "train_df.shape\n",
    "train_df.label.value_counts(dropna = False)\n",
    "test_df.shape\n",
    "test_df.label.value_counts(dropna = False)\n",
    "X_train = train_df[x_col]\n",
    "X_test = test_df[x_col]\n",
    "y_train = train_df.label\n",
    "y_test = test_df.label\n",
    "#检查数据量是否一致\n",
    "X_train.shape[0] == y_train.shape[0]\n",
    "X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = x_col\n",
    "# time1 = time.time()\n",
    "# wrong_list= []\n",
    "# for index,value in enumerate(feature_list):\n",
    "#     print(index,value)\n",
    "#     try:\n",
    "#         pt.univariate_chart(df = all_df.copy(), col = value , target ='label' , n = 5,\n",
    "#                              special_attribute = [-1, np.nan],\n",
    "#                              dftrain=train_df.copy(), dftest=test_df.copy(),\n",
    "#                              draw_all=True, draw_train_test=True,result_path = result_path)\n",
    "#     except Exception as e:\n",
    "#         wrong_list.append(value)\n",
    "#         print(e)\n",
    "# wrong_list\n",
    "# time2 = time.time()\n",
    "# print('run_time: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算XGB importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.79%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>指标英文</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Snaptube</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>cnt_len_isover13</td>\n",
       "      <td>0.023673</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Calculadora</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Santander</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 指标英文  importance  importance_rank\n",
       "195          Snapchat    0.027000              1.0\n",
       "284          Snaptube    0.024027              2.0\n",
       "272  cnt_len_isover13    0.023673              3.0\n",
       "285       Calculadora    0.023137              4.0\n",
       "274         Santander    0.021941              5.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "## prediction\n",
    "y_pred = model.predict(X_test);\n",
    "predictions = [round(value) for value in y_pred]\n",
    "## evaluation\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "features_in_model = x_col\n",
    "feature_importance = model.feature_importances_\n",
    "var_importance = pd.DataFrame(columns=[\"指标英文\", 'importance'])\n",
    "var_importance['指标英文'] = features_in_model\n",
    "var_importance['importance'] = feature_importance\n",
    "var_importance.loc[:, 'importance_rank'] = var_importance.importance.rank(ascending=False)\n",
    "var_importance.sort_values(by = 'importance',ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overall_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'按训练集和验证集检查变量的稳定性和有效性'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(445, 444)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_time:  52.57714772224426\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "args_dict = {\n",
    "    'random_forest': {\n",
    "        'grid_search': False,\n",
    "        'param': None\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'grid_search': False,\n",
    "        'param': None\n",
    "    }\n",
    "}\n",
    "methods = [\n",
    "    'random_forest',\n",
    "    #'lasso',\n",
    "    #'xgboost'\n",
    "]\n",
    "\n",
    "time1 = time.time()\n",
    "## Train 分箱,为了得到分箱的woe值\n",
    "X_cat_train, X_transformed_train, woe_iv_df, rebin_spec, ranking_result = fs_obj.overall_ranking(X_train, y_train,\n",
    "                                                                                           var_dict, args_dict,\n",
    "                                                                                           methods, num_max_bins=5)\n",
    "\n",
    "woe_iv_df.to_excel(os.path.join(result_path,'woe_iv_df.xlsx'))\n",
    "ranking_result.to_excel(os.path.join(result_path,'ranking_result.xlsx'))\n",
    "\n",
    "rebin_spec = mu.convert_rebin_spec2XGB_rebin_spec(rebin_spec)\n",
    "rebin_spec_bin_adjusted = {k: v for k, v in rebin_spec.items()}\n",
    "\n",
    "bin_obj = mt.BinWoe()\n",
    "X_cat_train = bin_obj.convert_to_category(X_train, var_dict, rebin_spec_bin_adjusted)\n",
    "X_cat_test = bin_obj.convert_to_category(X_test, var_dict, rebin_spec_bin_adjusted)\n",
    "\n",
    "\"\"\"按训练集和验证集检查变量的稳定性和有效性\"\"\"\n",
    "## train\n",
    "train_df['appmon'] = '0_train'\n",
    "test_df['appmon'] = '1_test'\n",
    "\n",
    "all_cat = pd.concat([X_cat_train,X_cat_test])\n",
    "app_data = pd.concat([train_df[['label','appmon']],test_df[['label','appmon']]])\n",
    "X_cat_with_y_appmon_all = pd.merge(all_cat,app_data[['label','appmon']] ,left_index=True,right_index=True)\n",
    "X_cat_with_y_appmon_all.shape\n",
    "\n",
    "var_dist_badRate_by_time_all = ss.get_badRate_and_dist_by_time(X_cat_with_y_appmon_all,list([i for i in all_cat.columns if i != 'loan_id']),'appmon','label')\n",
    "var_dist_badRate_by_time_all.to_excel(os.path.join(result_path, 'var_dist_badRate_by_sample.xlsx'))\n",
    "\n",
    "# PSI\n",
    "var_psi = pf.variable_psi(X_cat_train, X_cat_test, var_dict)\n",
    "var_psi.loc[:, 'psi_rank'] = var_psi.PSI.rank(ascending=False)\n",
    "var_psi.to_excel(os.path.join(result_path, 'var_PSI.xlsx'))\n",
    "\n",
    "# 汇总各项指标\n",
    "# var_psi.drop(['数据源','指标中文'],axis = 1,inplace=True)\n",
    "ranking_result_all = ranking_result.merge(var_importance, on='指标英文', how='left').merge(var_psi, on='指标英文', how='left')\n",
    "ranking_result_all.to_excel(os.path.join(result_path,'ranking_result_all.xlsx'))\n",
    "\n",
    "time2 = time.time()\n",
    "print('run_time: ', time2-time1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "变量总个数442\n",
      "PSI筛掉的个数34\n",
      "IV筛掉的个数357\n",
      "xgb重要性筛掉的个数0\n",
      "相关性特征筛掉的个数333\n",
      "univariate斜率特征筛掉的个数99\n",
      "总共筛掉的个数414\n",
      "剩余变量个数28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_time:  22.751505136489868\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "train = train_df.drop(useless_col,axis = 1).drop('appmon',axis = 1)\n",
    "test = test_df.drop(useless_col,axis = 1).drop('appmon',axis = 1)\n",
    "f_rmv = feature_remove(train,test, ranking_result_all, result_path, psi = 0.1, iv = 0.02, imp = 0, corr = 0.65, slope = 'TRUE')\n",
    "\n",
    "try:\n",
    "    train = train.drop(['slope'], axis=1)\n",
    "    test = test.drop(['slope'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "feature_used = list(set(x_col) - set(f_rmv))\n",
    "len(feature_used)\n",
    "X_train = train_df[feature_used]\n",
    "X_test = test_df[feature_used]\n",
    "time2 = time.time()\n",
    "print('run_time: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature_used = pd.read_excel(os.path.join(input_path,'selected_var.xlsx'))\n",
    "# feature_used = pd.read_excel(os.path.join(result_path,'temp.xlsx'))\n",
    "# feature_used = list(feature_used['selected_var'])\n",
    "# len(feature_used)\n",
    "# train1 = train_df[feature_used +['label']] \n",
    "# test1 = test_df[feature_used +['label']] \n",
    "# f_rmv1 = feature_remove(train1,test1, ranking_result_all, result_path, psi = -1, iv = 0.001, imp = 0, corr = 0.9, slope = 'TRUE')\n",
    "# feature_used = list(set(feature_used) - set(f_rmv1))\n",
    "# len(feature_used)\n",
    "# X_train = train_df[feature_used]\n",
    "# X_test = test_df[feature_used]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量分箱并替换WOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_time:  2.8525099754333496\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "# var_dict = pd.read_csv(os.path.join(input_path,'dict_all.csv'))\n",
    "# var_dict = var_dict[var_dict['指标英文'].isin(feature_used)]\n",
    "# var_dict.shape\n",
    "## Train 分箱\n",
    "X_cat_train, X_transformed, woe_iv_df, rebin_spec, ranking_result = fs_obj.overall_ranking(X_train, y_train,\n",
    "                                                                                           var_dict, args_dict,\n",
    "                                                                                           methods, num_max_bins=5)\n",
    "\n",
    "save_data_to_pickle(X_cat_train,result_path,'X_cat_train.pkl')\n",
    "save_data_to_pickle(woe_iv_df,result_path,'woe_iv_df.pkl')\n",
    "save_data_to_pickle(rebin_spec,result_path,'rebin_spec.pkl')\n",
    "save_data_to_pickle(X_transformed,result_path,'X_transformed.pkl')\n",
    "save_data_to_pickle(ranking_result,result_path,'ranking_result.pkl')\n",
    "\n",
    "rebin_spec = mu.convert_rebin_spec2XGB_rebin_spec(rebin_spec)\n",
    "rebin_spec_bin_adjusted = {k:v for k,v in rebin_spec.items()}\n",
    "\n",
    "bin_obj = mt.BinWoe()\n",
    "\n",
    "X_cat_train = bin_obj.convert_to_category(X_train, var_dict, rebin_spec_bin_adjusted)\n",
    "woe_iv_df_coarse = bin_obj.calculate_woe_all(X_cat_train, y_train, var_dict, rebin_spec_bin_adjusted)\n",
    "X_transformed_train= bin_obj.transform_x_all(X_cat_train, woe_iv_df_coarse)\n",
    "save_data_to_pickle(woe_iv_df_coarse,result_path,'woe_iv_df_coarse.pkl')\n",
    "woe_iv_df_coarse.to_excel(os.path.join(result_path,'woe_iv_df_coarse.xlsx'))\n",
    "\n",
    "X_cat_test = bin_obj.convert_to_category(X_test, var_dict, rebin_spec_bin_adjusted)\n",
    "X_transformed_test= bin_obj.transform_x_all(X_cat_test, woe_iv_df_coarse)\n",
    "\n",
    "time2 = time.time()\n",
    "print('run_time: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426474\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                  333\n",
      "Model:                          Logit   Df Residuals:                      304\n",
      "Method:                           MLE   Df Model:                           28\n",
      "Date:                Wed, 18 Mar 2020   Pseudo R-squ.:                  0.2060\n",
      "Time:                        23:37:00   Log-Likelihood:                -142.02\n",
      "converged:                       True   LL-Null:                       -178.86\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.580e-06\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "email1_gmail             0.8776      0.796      1.103      0.270      -0.682       2.437\n",
      "bank_number_0237         0.7639      1.211      0.631      0.528      -1.609       3.137\n",
      "income                   1.0314      0.385      2.678      0.007       0.276       1.786\n",
      "maritial_status_V        0.2544      0.735      0.346      0.729      -1.186       1.695\n",
      "state_name_CE            1.1712      0.960      1.220      0.222      -0.710       3.052\n",
      "model_SM-G610M           0.7212      0.853      0.846      0.398      -0.951       2.393\n",
      "cnt_len_is10             1.1408      0.450      2.536      0.011       0.259       2.022\n",
      "bank_number_0033         0.6295      1.360      0.463      0.643      -2.036       3.295\n",
      "maritial_status_S       -0.1106      1.428     -0.077      0.938      -2.909       2.687\n",
      "education_degree_5       1.6077      0.955      1.683      0.092      -0.265       3.480\n",
      "state_name_RS            0.8124      0.966      0.841      0.400      -1.081       2.705\n",
      "board_MSM8953            0.6196      0.689      0.900      0.368      -0.730       1.969\n",
      "state_name_SC            0.1854      0.721      0.257      0.797      -1.227       1.598\n",
      "bank_number_0104         0.7339      1.403      0.523      0.601      -2.015       3.483\n",
      "education_degree_7       0.3375      0.652      0.518      0.605      -0.940       1.615\n",
      "email1_live              1.8739      0.944      1.985      0.047       0.024       3.724\n",
      "maritial_status_C        0.9795      1.492      0.656      0.512      -1.946       3.905\n",
      "education_degree_3       1.8488      0.823      2.247      0.025       0.236       3.461\n",
      "bank_number_0341         0.0003      1.169      0.000      1.000      -2.290       2.291\n",
      "active_companies         1.7076      0.790      2.160      0.031       0.158       3.257\n",
      "model_moto g(6) play     1.0635      0.953      1.116      0.264      -0.803       2.930\n",
      "state_name_SP           -0.5626      1.233     -0.456      0.648      -2.980       1.854\n",
      "net_type                 1.4650      0.738      1.985      0.047       0.019       2.912\n",
      "screen_(1193, 720)       0.9582      0.650      1.473      0.141      -0.317       2.233\n",
      "rate_len_is11            0.8178      0.686      1.193      0.233      -0.526       2.162\n",
      "rate_mid_freq_app        0.8223      0.334      2.465      0.014       0.168       1.476\n",
      "screen_(1384, 720)       0.9047      0.614      1.474      0.140      -0.298       2.107\n",
      "manufacture_SAMSUNG     -0.2028      0.947     -0.214      0.830      -2.059       1.654\n",
      "intercept               -1.5698      0.188     -8.365      0.000      -1.938      -1.202\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_transformed_train['intercept'] = [1]*X_transformed_train.shape[0]\n",
    "LR = sm.Logit(y_train,X_transformed_train).fit()\n",
    "print(LR.summary())\n",
    "pvalues = LR.pvalues.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_number_0341\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426474\n",
      "         Iterations 7\n",
      "maritial_status_S\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426483\n",
      "         Iterations 7\n",
      "manufacture_SAMSUNG\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426555\n",
      "         Iterations 7\n",
      "state_name_SC\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426664\n",
      "         Iterations 7\n",
      "maritial_status_V\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426876\n",
      "         Iterations 7\n",
      "state_name_SP\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427130\n",
      "         Iterations 7\n",
      "education_degree_7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427563\n",
      "         Iterations 7\n",
      "bank_number_0033\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.428067\n",
      "         Iterations 7\n",
      "bank_number_0104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.428360\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                  333\n",
      "Model:                          Logit   Df Residuals:                      313\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Wed, 18 Mar 2020   Pseudo R-squ.:                  0.2025\n",
      "Time:                        23:37:01   Log-Likelihood:                -142.64\n",
      "converged:                       True   LL-Null:                       -178.86\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.600e-08\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "email1_gmail             0.9773      0.784      1.247      0.212      -0.559       2.513\n",
      "bank_number_0237         1.0263      0.900      1.140      0.254      -0.738       2.790\n",
      "income                   1.0308      0.378      2.724      0.006       0.289       1.772\n",
      "state_name_CE            1.2272      0.941      1.304      0.192      -0.617       3.072\n",
      "model_SM-G610M           0.7064      0.836      0.845      0.398      -0.933       2.345\n",
      "cnt_len_is10             1.0845      0.407      2.662      0.008       0.286       1.883\n",
      "education_degree_5       1.9987      0.792      2.523      0.012       0.446       3.552\n",
      "state_name_RS            0.8191      0.946      0.866      0.386      -1.034       2.673\n",
      "board_MSM8953            0.5387      0.588      0.917      0.359      -0.613       1.691\n",
      "email1_live              1.8459      0.920      2.006      0.045       0.043       3.649\n",
      "maritial_status_C        0.8983      0.964      0.932      0.351      -0.991       2.787\n",
      "education_degree_3       2.1761      0.729      2.983      0.003       0.746       3.606\n",
      "active_companies         1.7833      0.776      2.297      0.022       0.262       3.305\n",
      "model_moto g(6) play     1.2463      0.922      1.352      0.176      -0.561       3.053\n",
      "net_type                 1.5635      0.725      2.158      0.031       0.143       2.984\n",
      "screen_(1193, 720)       0.8524      0.594      1.435      0.151      -0.312       2.017\n",
      "rate_len_is11            0.7599      0.627      1.211      0.226      -0.470       1.990\n",
      "rate_mid_freq_app        0.8605      0.327      2.633      0.008       0.220       1.501\n",
      "screen_(1384, 720)       0.9305      0.606      1.536      0.124      -0.256       2.117\n",
      "intercept               -1.5862      0.187     -8.479      0.000      -1.953      -1.220\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ### 有些变量不显著，需要逐步剔除\n",
    "pvals = LR.pvalues\n",
    "multi_analysis = feature_used\n",
    "len(multi_analysis)\n",
    "varLargeP = {k: v for k,v in pvals.items() if v >= 0.5}\n",
    "varLargeP = sorted(varLargeP.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "while(len(varLargeP) > 0 and len(multi_analysis) > 0):\n",
    "    # 每次迭代中，剔除不显著的变量，直到\n",
    "    # (1) 剩余所有变量均显著\n",
    "    # (2) 没有特征可选\n",
    "    varMaxP = varLargeP[0][0]\n",
    "    print(varMaxP)\n",
    "    if varMaxP == 'intercept':\n",
    "        print('the intercept is not significant!')\n",
    "        break\n",
    "    multi_analysis.remove(varMaxP)\n",
    "    y = y_train\n",
    "    X = X_transformed_train[multi_analysis]\n",
    "    X['intercept'] = [1] * X.shape[0]\n",
    "    LR_final = sm.Logit(y, X).fit()\n",
    "    pvals = LR_final.pvalues\n",
    "    pvals = pvals.to_dict()\n",
    "    varLargeP = {k: v for k, v in pvals.items() if v >= 0.5}\n",
    "    varLargeP = sorted(varLargeP.items(), key=lambda d: d[1], reverse=True)\n",
    "\n",
    "print(LR_final.summary())\n",
    "frame = LR_final.params.to_frame(name = 'coef').merge(LR_final.pvalues.to_frame(name = 'P>|z|'),\n",
    "                                              left_index = True,right_index = True,how = 'left')\n",
    "frame.to_excel(os.path.join(result_path,'model_result.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2229500750445341\n"
     ]
    }
   ],
   "source": [
    "X = np.matrix(X_transformed_train[feature_used])\n",
    "VIF_list = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "max_VIF = max(VIF_list)\n",
    "print(max_VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed_train[feature_used].corr().to_excel(os.path.join(result_path,'corr.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel =open(os.path.join(result_path,'LR_Model_Normal.pkl'),'wb')\n",
    "pickle.dump(LR_final,saveModel)\n",
    "saveModel.close()\n",
    "\n",
    "##加载模型\n",
    "# modelFile =open(result_path+'LR_Model_Normal.pkl','rb')\n",
    "# LR = pickle.load(modelFile)\n",
    "# modelFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pf.data_score_KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yantingting/opt/anaconda3/envs/modeling/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "calculate_ks_by_decile_proba() missing 1 required positional argument: 'q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-515f1bb56ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata_scored_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_proba_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_proba_ks_20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score_ks_20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_scored_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_proba_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_proba_ks_20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score_ks_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_score_KS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ks.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/modeling/metrics.py\u001b[0m in \u001b[0;36mdata_score_KS\u001b[0;34m(self, train, test, pre_label, n1, n2)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0;31m# def data_KS(self, train, test, pre_label, n1,n2,method='proba'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m     \u001b[0;31m#     #### TRAIN ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m#     y_train = train.label.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_ks_by_decile_proba() missing 1 required positional argument: 'q'"
     ]
    }
   ],
   "source": [
    "X_transformed_test['intercept']=[1]*X_transformed_test.shape[0]\n",
    "y_train_pred = LR_final.predict(X_transformed_train[feature_used + ['intercept']])\n",
    "y_train_pred.shape\n",
    "y_test_pred = LR_final.predict(X_transformed_test[feature_used + ['intercept']])\n",
    "y_test_pred.shape\n",
    "# ### 打分&KS\n",
    "train_pred = train_df.copy()\n",
    "train_pred['y_pred'] = y_train_pred\n",
    "\n",
    "test_pred = test_df.copy()\n",
    "test_pred['y_pred'] = y_test_pred\n",
    "data_scored_train, train_proba_ks, train_proba_ks_20, train_score_ks, train_score_ks_20, data_scored_test, test_proba_ks, test_proba_ks_20, test_score_ks, test_score_ks_20 = pf.data_score_KS(train_pred, test_pred, 'y_pred',n1 = 5,n2 = 10)\n",
    "\n",
    "writer = pd.ExcelWriter(os.path.join(result_path,'ks.xlsx'))\n",
    "train_score_ks.to_excel(writer,sheet_name = 'train_score_ks')\n",
    "test_score_ks.to_excel(writer, sheet_name = 'test_score_ks') \n",
    "writer.close()\n",
    "\n",
    "\n",
    "def auc_acc_table(df):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    y = df.label.values\n",
    "    y_pred = df.y_pred\n",
    "    ## AUC\n",
    "    auc = roc_auc_score(y, y_pred)\n",
    "    print(\"auc: %.2f\" % auc)\n",
    "    ## Accuracy\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    print(\"Accuracy: %.4f%%\" % (accuracy * 100.0))\n",
    "    return auc, accuracy\n",
    "\n",
    "auc_train, acc_train = auc_acc_table(train_pred)\n",
    "auc_test, acc_test = auc_acc_table(test_pred)\n",
    "print('success')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pf.calculate_ks_by_decile_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiftChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data_scored\n",
    "data_scored_train['sample_set'] = \"train\"\n",
    "data_scored_test['sample_set'] = \"test\"\n",
    "data_scored_all = pd.concat([data_scored_train, data_scored_test])\n",
    "data_scored_all['order_no'] = data_scored_all['order_no'].astype(str)\n",
    "data_scored_all.head()\n",
    "save_data_to_pickle(data_scored_all,result_path,'data_scored_all.pkl')\n",
    "\n",
    "FIG_PATH = os.path.join(result_path, 'figure', 'liftchart')\n",
    "if not os.path.exists(FIG_PATH):\n",
    "    os.makedirs(FIG_PATH)\n",
    "\n",
    "train_lc = pt.show_result_new(data_scored_all.loc[data_scored_all.sample_set == 'train'], 'y_pred','Y', n_bins = 5, feature_label='train')\n",
    "test_lc = pt.show_result_new(data_scored_all.loc[data_scored_all.sample_set == 'test'], 'y_pred','Y', n_bins = 5, feature_label='test')\n",
    "# oot_lc = pt.show_result_new(data_scored_all.loc[data_scored_all.sample_set == 'oot'], 'y_pred','Y', n_bins = 10, feature_label='oot')\n",
    "path = os.path.join(FIG_PATH, \"LiftChart.png\")\n",
    "plt.savefig(path, format='png', dpi=300, bbox_inches = 'tight',pad_inches = 0.1)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_PATH = os.path.join(result_path, 'figure', 'PDP')\n",
    "if not os.path.exists(FIG_PATH):\n",
    "    os.makedirs(FIG_PATH)\n",
    "\n",
    "f_imp_list = LR_final.params.index.tolist()\n",
    "select_features =LR_final.params.index.tolist()\n",
    "all_pred = pd.concat([X_transformed_train, X_transformed_test])\n",
    "len(select_features)    \n",
    "    \n",
    "n = 0\n",
    "while n < len(f_imp_list):\n",
    "    m = n + 9\n",
    "    features_draw = [i for i in f_imp_list[n:m]]\n",
    "    pt.pdpCharts9(LR_final, all_pred, features_draw, select_features, n_bins=10, dfltValue=-1)\n",
    "    path = os.path.join(FIG_PATH, \"pdp_\" + str(n) + \"_\" + str(m) + \".png\")\n",
    "    plt.savefig(path, format='png', dpi=300, bbox_inches = 'tight',pad_inches = 0.1);\n",
    "    plt.close()\n",
    "    n += 9\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入模变量的univariate_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_var_path= os.path.join(result_path,'var_used')\n",
    "if not os.path.exists(result_var_path):\n",
    "    os.mkdir(result_var_path)\n",
    "    \n",
    "time1 = time.time()\n",
    "feature_list = feature_used\n",
    "wrong_list= []\n",
    "for index,value in enumerate(feature_list):\n",
    "    print(index,value)\n",
    "    try:\n",
    "        pt.univariate_chart(df = train_df.copy(), col = value , target ='label' , n = 5,\n",
    "                             special_attribute = [-1, np.nan],\n",
    "                             dftrain=train_df.copy(), dftest=test_df.copy(),\n",
    "                             draw_all=False, draw_train_test=True,result_path = result_var_path)\n",
    "    except Exception as e:\n",
    "        wrong_list.append(value)\n",
    "        print(e)\n",
    "wrong_list\n",
    "time2 = time.time()\n",
    "print('run_time: ',time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
